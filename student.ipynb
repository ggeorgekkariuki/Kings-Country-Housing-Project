{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: \n",
    "* Student pace: self paced / part time / full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING OF LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for reading our data\n",
    "import numpy as np  # for performing calculations\n",
    "import seaborn as sns # for visualization\n",
    "import matplotlib.pyplot as plt # for visualization\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.stats as stat # to calculate statistical operations\n",
    "\n",
    "from statsmodels.formula.api import ols #for creating a model\n",
    "\n",
    "from sklearn.model_selection import train_test_split # for performing train train_test_split on our data\n",
    "from sklearn.linear_model import LinearRegression # making a LinearRegression model\n",
    "from sklearn.metrics import mean_squared_error # for calculating error metrics to evaluate our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING DATA INTO A DATAFRAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>6 Low Average</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  10/13/2014  221900.0         3       1.00         1180   \n",
       "1  6414100192   12/9/2014  538000.0         3       2.25         2570   \n",
       "2  5631500400   2/25/2015  180000.0         2       1.00          770   \n",
       "3  2487200875   12/9/2014  604000.0         4       3.00         1960   \n",
       "4  1954400510   2/18/2015  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors waterfront  view  ...          grade sqft_above  \\\n",
       "0      5650     1.0        NaN  NONE  ...      7 Average       1180   \n",
       "1      7242     2.0         NO  NONE  ...      7 Average       2170   \n",
       "2     10000     1.0         NO  NONE  ...  6 Low Average        770   \n",
       "3      5000     1.0         NO  NONE  ...      7 Average       1050   \n",
       "4      8080     1.0         NO  NONE  ...         8 Good       1680   \n",
       "\n",
       "   sqft_basement yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0            0.0     1955           0.0    98178  47.5112 -122.257   \n",
       "1          400.0     1951        1991.0    98125  47.7210 -122.319   \n",
       "2            0.0     1933           NaN    98028  47.7379 -122.233   \n",
       "3          910.0     1965           0.0    98136  47.5208 -122.393   \n",
       "4            0.0     1987           0.0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc_data_df = pd.read_csv('data/kc_house_data.csv') # reading our data into a pandas data frame\n",
    "kc_data_df.head() # checking the first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explore our data  by creating a function  data_summary to show us the info and shape of our data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_summary(data):# a function that gives us a brief summary of our data frame\n",
    " # Shape of Data\n",
    "  shape = data.shape\n",
    "  # Info of Data\n",
    "  info = data.info()  \n",
    "\n",
    "  # Combining the information into a single string\n",
    "  summary = f\"Dataframe Shape: {shape}\\n\"\n",
    "  summary += f\"Dataframe Info:\\n{info}\"  \n",
    "\n",
    "  return summary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21597 non-null  int64  \n",
      " 1   date           21597 non-null  object \n",
      " 2   price          21597 non-null  float64\n",
      " 3   bedrooms       21597 non-null  int64  \n",
      " 4   bathrooms      21597 non-null  float64\n",
      " 5   sqft_living    21597 non-null  int64  \n",
      " 6   sqft_lot       21597 non-null  int64  \n",
      " 7   floors         21597 non-null  float64\n",
      " 8   waterfront     19221 non-null  object \n",
      " 9   view           21534 non-null  object \n",
      " 10  condition      21597 non-null  object \n",
      " 11  grade          21597 non-null  object \n",
      " 12  sqft_above     21597 non-null  int64  \n",
      " 13  sqft_basement  21597 non-null  object \n",
      " 14  yr_built       21597 non-null  int64  \n",
      " 15  yr_renovated   17755 non-null  float64\n",
      " 16  zipcode        21597 non-null  int64  \n",
      " 17  lat            21597 non-null  float64\n",
      " 18  long           21597 non-null  float64\n",
      " 19  sqft_living15  21597 non-null  int64  \n",
      " 20  sqft_lot15     21597 non-null  int64  \n",
      "dtypes: float64(6), int64(9), object(6)\n",
      "memory usage: 3.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dataframe Shape: (21597, 21)\\nDataframe Info:\\nNone'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_summary(kc_data_df) # using the function to obtain a summary of our dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At these stage we will clean our data using the following steps\n",
    "\n",
    ". **Completeness** (we will check for missing values , how they affect our data set and how we will handle them)\n",
    "\n",
    ". **Consistency** (we will check for duplicate values and how to handle them)\n",
    "\n",
    ". **Uniformity** ( we will check the data types as well as our columns naming for uniformity)\n",
    "\n",
    ". **Validity** (we will handlle irrelevant columns and  check for outliers )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPLETENESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "date                0\n",
       "price               0\n",
       "bedrooms            0\n",
       "bathrooms           0\n",
       "sqft_living         0\n",
       "sqft_lot            0\n",
       "floors              0\n",
       "waterfront       2376\n",
       "view               63\n",
       "condition           0\n",
       "grade               0\n",
       "sqft_above          0\n",
       "sqft_basement       0\n",
       "yr_built            0\n",
       "yr_renovated     3842\n",
       "zipcode             0\n",
       "lat                 0\n",
       "long                0\n",
       "sqft_living15       0\n",
       "sqft_lot15          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking and summing up our missing values in our data set\n",
    "kc_data_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to have missing values in our waterfront(2376),view(63) and yr_renovated(3842). We will have to investigate further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column waterfront has 2376 missing values, which is 11.0 % of it's total\n",
      "The column view has 63 missing values, which is 0.3 % of it's total\n",
      "The column yr_renovated has 3842 missing values, which is 17.8 % of it's total\n"
     ]
    }
   ],
   "source": [
    "# lets check for the percentage of missing values in our data set\n",
    "for col in kc_data_df.columns: # we are using a for loop to iterate over our data\n",
    "    if kc_data_df[col].isnull().sum() > 0:\n",
    "        percentage = (kc_data_df[col].isnull().sum()/len(kc_data_df[col]))*100\n",
    "        print(\"The column\", col,\"has\",kc_data_df[col].isnull().sum(),\"missing values, which is\", round(percentage, 1),\"% of it's total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets further check each column with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Waterfront column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check for the value count of the unique elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Waterfront Column\n",
      "\n",
      "Number of distinct elements is: 2 \n",
      "\n",
      "This is the count of unique values:\n",
      "NO     19075\n",
      "YES      146\n",
      "Name: waterfront, dtype: int64 \n",
      "\n",
      "The unique values:\n",
      "[nan 'NO' 'YES'] \n",
      "\n",
      "Number of missing values: 2376\n"
     ]
    }
   ],
   "source": [
    "#checking for unique elements value count\n",
    "print(\"The Waterfront Column\\n\")\n",
    "\n",
    "print(\"Number of distinct elements is:\", kc_data_df['waterfront'].nunique(),\"\\n\")\n",
    "\n",
    "print(\"This is the count of unique values:\")\n",
    "print(kc_data_df['waterfront'].value_counts(),\"\\n\")\n",
    "\n",
    "print('The unique values:')\n",
    "print(kc_data_df['waterfront'].unique(),\"\\n\")\n",
    "\n",
    "print(\"Number of missing values:\",kc_data_df['waterfront'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two unique values are YES and NO.NO is the most common value in this column with(19875) entries, whilst YES has just (146). This indicates that the majority of these homes lack a waterfront, hence it seems reasonable to presume that the homes with missing values  lack a waterfront. it is safe to substitute the missing values with NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO     21451\n",
      "YES      146\n",
      "Name: waterfront, dtype: int64\n",
      "['NO' 'YES']\n"
     ]
    }
   ],
   "source": [
    "# replacing missing values with 'NO'\n",
    "kc_data_df['waterfront'].fillna('NO',inplace=True)\n",
    "\n",
    "# confirming if the missing values have been replaced\n",
    "print(kc_data_df['waterfront'].value_counts())\n",
    "print(kc_data_df['waterfront'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The change was successful because the number of NO entries increased from 19875 to 21451."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###### View column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a function to get our unique elements and sum up there value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_counts(data, column): # creating a function for checking for unique elements and ther counts\n",
    "    print(\"Number of distinct elements in\", column, \"column:\", data[column].nunique())  # checking for unique elements in the column\n",
    "\n",
    "    value_counts = data[column].value_counts()  # counting the value of each unique element\n",
    "\n",
    "    # Use Series.apply with a Lambda Function\n",
    "    format_lambda = lambda x: f\"{x}: {value_counts[x]} ({value_counts[x] / len(data) * 100:.1f}%)\"\n",
    "\n",
    "    formatted_counts = value_counts.index.map(format_lambda)  # it will execute without creating the formatted_counts variable or printing its contents.\n",
    "    print(formatted_counts)\n",
    "\n",
    "    print(f\"\\nMissing values:\", data[column].isnull().sum())  # combining the information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct elements in view column: 5\n",
      "Index(['NONE: 19422 (89.9%)', 'AVERAGE: 957 (4.4%)', 'GOOD: 508 (2.4%)',\n",
      "       'FAIR: 330 (1.5%)', 'EXCELLENT: 317 (1.5%)'],\n",
      "      dtype='object')\n",
      "\n",
      "Missing values: 63\n"
     ]
    }
   ],
   "source": [
    "unique_counts(kc_data_df,'view')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this column, NONE is the most frequent unique element. This indicates that the 63 missing values are representing homes  that don't have a view. Hence I WILL substitute  the missing values with NONE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NONE         19485\n",
      "AVERAGE        957\n",
      "GOOD           508\n",
      "FAIR           330\n",
      "EXCELLENT      317\n",
      "Name: view, dtype: int64\n",
      "['NONE' 'GOOD' 'EXCELLENT' 'AVERAGE' 'FAIR']\n"
     ]
    }
   ],
   "source": [
    "# replacing missing values with 'NONE'\n",
    "kc_data_df['view'].fillna('NONE',inplace=True)\n",
    "\n",
    "# confirming if the missing values have been replaced\n",
    "print(kc_data_df['view'].value_counts())\n",
    "print(kc_data_df['view'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes successfully made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Yr_renovated column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct elements in yr_renovated column: 70\n",
      "Index(['0.0: 17011 (78.8%)', '2014.0: 73 (0.3%)', '2003.0: 31 (0.1%)',\n",
      "       '2013.0: 31 (0.1%)', '2007.0: 30 (0.1%)', '2000.0: 29 (0.1%)',\n",
      "       '2005.0: 29 (0.1%)', '1990.0: 22 (0.1%)', '2004.0: 22 (0.1%)',\n",
      "       '2009.0: 21 (0.1%)', '1989.0: 20 (0.1%)', '2006.0: 20 (0.1%)',\n",
      "       '2002.0: 17 (0.1%)', '1991.0: 16 (0.1%)', '1998.0: 16 (0.1%)',\n",
      "       '1984.0: 16 (0.1%)', '1999.0: 15 (0.1%)', '2008.0: 15 (0.1%)',\n",
      "       '2010.0: 15 (0.1%)', '2001.0: 15 (0.1%)', '1983.0: 15 (0.1%)',\n",
      "       '2015.0: 14 (0.1%)', '1985.0: 14 (0.1%)', '1986.0: 14 (0.1%)',\n",
      "       '1987.0: 14 (0.1%)', '1994.0: 14 (0.1%)', '1992.0: 13 (0.1%)',\n",
      "       '1993.0: 12 (0.1%)', '1997.0: 12 (0.1%)', '1995.0: 12 (0.1%)',\n",
      "       '1996.0: 11 (0.1%)', '1988.0: 11 (0.1%)', '1970.0: 9 (0.0%)',\n",
      "       '2011.0: 9 (0.0%)', '1980.0: 8 (0.0%)', '1982.0: 8 (0.0%)',\n",
      "       '2012.0: 8 (0.0%)', '1979.0: 7 (0.0%)', '1977.0: 7 (0.0%)',\n",
      "       '1968.0: 7 (0.0%)', '1975.0: 5 (0.0%)', '1964.0: 5 (0.0%)',\n",
      "       '1969.0: 4 (0.0%)', '1963.0: 4 (0.0%)', '1973.0: 4 (0.0%)',\n",
      "       '1981.0: 4 (0.0%)', '1965.0: 4 (0.0%)', '1978.0: 3 (0.0%)',\n",
      "       '1960.0: 3 (0.0%)', '1958.0: 3 (0.0%)', '1956.0: 3 (0.0%)',\n",
      "       '1955.0: 3 (0.0%)', '1945.0: 3 (0.0%)', '1972.0: 3 (0.0%)',\n",
      "       '1967.0: 2 (0.0%)', '1957.0: 2 (0.0%)', '1940.0: 2 (0.0%)',\n",
      "       '1974.0: 2 (0.0%)', '1962.0: 2 (0.0%)', '1953.0: 1 (0.0%)',\n",
      "       '1950.0: 1 (0.0%)', '1934.0: 1 (0.0%)', '1944.0: 1 (0.0%)',\n",
      "       '1976.0: 1 (0.0%)', '1948.0: 1 (0.0%)', '1946.0: 1 (0.0%)',\n",
      "       '1959.0: 1 (0.0%)', '1971.0: 1 (0.0%)', '1951.0: 1 (0.0%)',\n",
      "       '1954.0: 1 (0.0%)'],\n",
      "      dtype='object')\n",
      "\n",
      "Missing values: 3842\n"
     ]
    }
   ],
   "source": [
    "unique_counts(kc_data_df,'yr_renovated' )# using the unique_count function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The years span from 1948–2014 and 0.0 is the most frequent value thus  we'll replace the missing values with 0.0 because we don't know what 0.0 means based  on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0       20853\n",
      "2014.0       73\n",
      "2003.0       31\n",
      "2013.0       31\n",
      "2007.0       30\n",
      "          ...  \n",
      "1946.0        1\n",
      "1959.0        1\n",
      "1971.0        1\n",
      "1951.0        1\n",
      "1954.0        1\n",
      "Name: yr_renovated, Length: 70, dtype: int64\n",
      "[   0. 1991. 2002. 2010. 1992. 2013. 1994. 1978. 2005. 2003. 1984. 1954.\n",
      " 2014. 2011. 1983. 1945. 1990. 1988. 1977. 1981. 1995. 2000. 1999. 1998.\n",
      " 1970. 1989. 2004. 1986. 2007. 1987. 2006. 1985. 2001. 1980. 1971. 1979.\n",
      " 1997. 1950. 1969. 1948. 2009. 2015. 1974. 2008. 1968. 2012. 1963. 1951.\n",
      " 1962. 1953. 1993. 1996. 1955. 1982. 1956. 1940. 1976. 1946. 1975. 1964.\n",
      " 1973. 1957. 1959. 1960. 1967. 1965. 1934. 1972. 1944. 1958.]\n"
     ]
    }
   ],
   "source": [
    "# replacing missing values with '0.0'\n",
    "kc_data_df['yr_renovated'].fillna(0.0,inplace=True)\n",
    "\n",
    "# confirming if the missing values have been replaced\n",
    "print(kc_data_df['yr_renovated'].value_counts())\n",
    "print(kc_data_df['yr_renovated'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The changes are made successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "date             0\n",
       "price            0\n",
       "bedrooms         0\n",
       "bathrooms        0\n",
       "sqft_living      0\n",
       "sqft_lot         0\n",
       "floors           0\n",
       "waterfront       0\n",
       "view             0\n",
       "condition        0\n",
       "grade            0\n",
       "sqft_above       0\n",
       "sqft_basement    0\n",
       "yr_built         0\n",
       "yr_renovated     0\n",
       "zipcode          0\n",
       "lat              0\n",
       "long             0\n",
       "sqft_living15    0\n",
       "sqft_lot15       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if there are any more missing values\n",
    "kc_data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### CONSISTENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for duplicate values\n",
    "kc_data_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNIFORMITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting  Data Types of Values in Columns from Object  to Float**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sqft_basement values are in objects data type, given that this column has numeric values.  let's try to investigate  the reason why the datatype isn't a float or integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       12826\n",
       "?           454\n",
       "600.0       217\n",
       "500.0       209\n",
       "700.0       208\n",
       "          ...  \n",
       "295.0         1\n",
       "417.0         1\n",
       "2050.0        1\n",
       "915.0         1\n",
       "704.0         1\n",
       "Name: sqft_basement, Length: 304, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc_data_df['sqft_basement'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These values represented by \"?\" string can be regarded as null values. We  will replace the \"?\"  with 0.0, because the majority of the values are at 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing the ? with 0.0\n",
    "kc_data_df['sqft_basement'].replace('?','0.0',inplace=True)\n",
    "\n",
    "#converting column to data type 'float'\n",
    "kc_data_df['sqft_basement'] = kc_data_df['sqft_basement'].astype(float)\n",
    "\n",
    "#confirming the change \n",
    "kc_data_df['sqft_basement'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully changed the data type to  a float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Converting the Date Column to month and year and Creating  new Columns  month and year**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The month and year the houses were sold are shown in the date column and data can be analysed easily by creating new columns called year and month  from this column, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after splitting date:\n",
      "           id     price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
      "0  7129300520  221900.0         3       1.00         1180      5650     1.0   \n",
      "1  6414100192  538000.0         3       2.25         2570      7242     2.0   \n",
      "2  5631500400  180000.0         2       1.00          770     10000     1.0   \n",
      "3  2487200875  604000.0         4       3.00         1960      5000     1.0   \n",
      "4  1954400510  510000.0         3       2.00         1680      8080     1.0   \n",
      "\n",
      "  waterfront  view  condition  ... sqft_basement  yr_built  yr_renovated  \\\n",
      "0         NO  NONE    Average  ...           0.0      1955           0.0   \n",
      "1         NO  NONE    Average  ...         400.0      1951        1991.0   \n",
      "2         NO  NONE    Average  ...           0.0      1933           0.0   \n",
      "3         NO  NONE  Very Good  ...         910.0      1965           0.0   \n",
      "4         NO  NONE    Average  ...           0.0      1987           0.0   \n",
      "\n",
      "   zipcode      lat     long  sqft_living15  sqft_lot15  month_sold  year_sold  \n",
      "0    98178  47.5112 -122.257           1340        5650          10       2014  \n",
      "1    98125  47.7210 -122.319           1690        7639          12       2014  \n",
      "2    98028  47.7379 -122.233           2720        8062           2       2015  \n",
      "3    98136  47.5208 -122.393           1360        5000          12       2014  \n",
      "4    98074  47.6168 -122.045           1800        7503           2       2015  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Spliting the date into month, day, and year\n",
    "date_split = kc_data_df['date'].str.split('/', expand=True)\n",
    "\n",
    "# Creating new columns for month and year and converting the values to integers\n",
    "kc_data_df['month_sold'] = date_split[0].astype(int)\n",
    "kc_data_df['year_sold'] = date_split[2].astype(int)\n",
    "\n",
    "# Droping the original date column\n",
    "kc_data_df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Verifying the changes\n",
    "print(\"DataFrame after splitting date:\")\n",
    "print(kc_data_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can seen the two columns have been  created and added to our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VALIDITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               5.185851e+09\n",
      "price            3.230000e+05\n",
      "bedrooms         1.000000e+00\n",
      "bathrooms        7.500000e-01\n",
      "sqft_living      1.120000e+03\n",
      "sqft_lot         5.645000e+03\n",
      "floors           1.000000e+00\n",
      "sqft_above       1.020000e+03\n",
      "sqft_basement    5.500000e+02\n",
      "yr_built         4.600000e+01\n",
      "yr_renovated     0.000000e+00\n",
      "zipcode          8.500000e+01\n",
      "lat              2.069000e-01\n",
      "long             2.030000e-01\n",
      "sqft_living15    8.700000e+02\n",
      "sqft_lot15       4.983000e+03\n",
      "month_sold       5.000000e+00\n",
      "year_sold        1.000000e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#checking for outliers using intequatrile for each column\n",
    "\n",
    "Q1 = kc_data_df.quantile(0.25) # First quartile\n",
    "Q3 = kc_data_df.quantile(0.75) # Third quartile\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have the above outliers lets visualize them using boxplots to investigate further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting box plots to visualize our outliers\n",
    "# Creating a list of column names excluding non-numeric columns (if any)\n",
    "numeric_columns = kc_data_df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Seting up the figure and axes\n",
    "fig, axes = plt.subplots(nrows=len(numeric_columns), figsize=(10, 6 * len(numeric_columns)))\n",
    "\n",
    "# Iterating over each numeric column and create a boxplot\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    ax = axes[i] if len(numeric_columns) > 1 else axes  # If there's only one numeric column, axes is not a list\n",
    "    \n",
    "    # Creating the boxplots\n",
    "    sns.boxplot(x=kc_data_df[column], ax=ax)\n",
    "    \n",
    "    # Seting titles and labels\n",
    "    ax.set_title(f'Boxplot of {column}')\n",
    "    ax.set_xlabel(column)\n",
    "    \n",
    "\n",
    "plt.tight_layout(pad=3.0)  # Adjusting the spacing between subplots\n",
    "plt.subplots_adjust(top=0.95)  # Adjusting the top margin to accommodate titles   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant amount of outliers in a number of our columns let remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the outliers \n",
    "# outliers_df_iqr = kc_data_df[~((kc_data_df < (Q1 - 1.5 * IQR)) |(kc_data_df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "print(outliers_df_iqr.shape) # The number of rows and columns in the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kc_data_df = outliers_df_iqr # storing our cleaned data in our original variable kc_data_df\n",
    "kc_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have removed our outliers  since they would have affected our model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create additional columns to determine the age of a house by getting the differnce between 2015 (that's when the data was last recorded) the reference year and yr_built, and another column age of the house after renovation by also getting the difference between 2015 and yr_renovated  \n",
    "\n",
    "These new columns will help to determine whether the age of built or renovation has an impact on the price of the house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column 'age_built' showing the age of house since its was built upto 2015\n",
    "kc_data_df['age_built'] = 2015 - kc_data_df['yr_built']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new column 'age_renovated'showing the age of a house after renovation\n",
    "kc_data_df['age_renovated'] = (2015 - kc_data_df['yr_renovated']).apply(lambda x: 0 if x == 2015 else x).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data_df.columns # checking to see if the two columns have been added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data_df.head(10) # viewing the first ten rows of our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets create a new column named  season_sold that tell us which at which season was a specific house sold at these will helps us to identify which season had the most sales and whether season determines the price of a house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a season dictonary using months in numerical order\n",
    "season_dict = {1:'Winter',\n",
    "           2:'Winter',\n",
    "           3:'Spring',\n",
    "           4:'Spring',\n",
    "           5:'Spring',\n",
    "           6:'Summer',\n",
    "           7:'Summer',\n",
    "           8:'Summer',\n",
    "           9:'Fall',\n",
    "           10:'Fall',\n",
    "           11:'Fall',\n",
    "           12:'Winter'}\n",
    "# creating a new column and mapping it to season_dict\n",
    "kc_data_df['season_sold'] = kc_data_df['month_sold'].map(season_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kc_data_df # checking if the new column was added"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
