{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: \n",
    "* Student pace: self paced / part time / full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING OF LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for reading our data\n",
    "import numpy as np  # for performing calculations\n",
    "import seaborn as sns # for visualization\n",
    "import matplotlib.pyplot as plt # for visualization\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.stats as stat # to calculate statistical operations\n",
    "\n",
    "from statsmodels.formula.api import ols #for creating a model\n",
    "\n",
    "from sklearn.model_selection import train_test_split # for performing train train_test_split on our data\n",
    "from sklearn.linear_model import LinearRegression # making a LinearRegression model\n",
    "from sklearn.metrics import mean_squared_error # for calculating error metrics to evaluate our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING DATA INTO A DATAFRAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>6 Low Average</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  10/13/2014  221900.0         3       1.00         1180   \n",
       "1  6414100192   12/9/2014  538000.0         3       2.25         2570   \n",
       "2  5631500400   2/25/2015  180000.0         2       1.00          770   \n",
       "3  2487200875   12/9/2014  604000.0         4       3.00         1960   \n",
       "4  1954400510   2/18/2015  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors waterfront  view  ...          grade sqft_above  \\\n",
       "0      5650     1.0        NaN  NONE  ...      7 Average       1180   \n",
       "1      7242     2.0         NO  NONE  ...      7 Average       2170   \n",
       "2     10000     1.0         NO  NONE  ...  6 Low Average        770   \n",
       "3      5000     1.0         NO  NONE  ...      7 Average       1050   \n",
       "4      8080     1.0         NO  NONE  ...         8 Good       1680   \n",
       "\n",
       "   sqft_basement yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0            0.0     1955           0.0    98178  47.5112 -122.257   \n",
       "1          400.0     1951        1991.0    98125  47.7210 -122.319   \n",
       "2            0.0     1933           NaN    98028  47.7379 -122.233   \n",
       "3          910.0     1965           0.0    98136  47.5208 -122.393   \n",
       "4            0.0     1987           0.0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc_data_df = pd.read_csv('data/kc_house_data.csv') # reading our data into a pandas data frame\n",
    "kc_data_df.head() # checking the first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explore our data  by creating a function  data_summary to show us the info and shape of our data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_summary(data):# a function that gives us a brief summary of our data frame\n",
    " # Shape of Data\n",
    "  shape = data.shape\n",
    "  # Info of Data\n",
    "  info = data.info()  \n",
    "\n",
    "  # Combining the information into a single string\n",
    "  summary = f\"Dataframe Shape: {shape}\\n\"\n",
    "  summary += f\"Dataframe Info:\\n{info}\"  \n",
    "\n",
    "  return summary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21597 non-null  int64  \n",
      " 1   date           21597 non-null  object \n",
      " 2   price          21597 non-null  float64\n",
      " 3   bedrooms       21597 non-null  int64  \n",
      " 4   bathrooms      21597 non-null  float64\n",
      " 5   sqft_living    21597 non-null  int64  \n",
      " 6   sqft_lot       21597 non-null  int64  \n",
      " 7   floors         21597 non-null  float64\n",
      " 8   waterfront     19221 non-null  object \n",
      " 9   view           21534 non-null  object \n",
      " 10  condition      21597 non-null  object \n",
      " 11  grade          21597 non-null  object \n",
      " 12  sqft_above     21597 non-null  int64  \n",
      " 13  sqft_basement  21597 non-null  object \n",
      " 14  yr_built       21597 non-null  int64  \n",
      " 15  yr_renovated   17755 non-null  float64\n",
      " 16  zipcode        21597 non-null  int64  \n",
      " 17  lat            21597 non-null  float64\n",
      " 18  long           21597 non-null  float64\n",
      " 19  sqft_living15  21597 non-null  int64  \n",
      " 20  sqft_lot15     21597 non-null  int64  \n",
      "dtypes: float64(6), int64(9), object(6)\n",
      "memory usage: 3.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dataframe Shape: (21597, 21)\\nDataframe Info:\\nNone'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_summary(kc_data_df) # using the function to obtain a summary of our dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At these stage we will clean our data using the following steps\n",
    "\n",
    ". **Completeness** (we will check for missing values , how they affect our data set and how we will handle them)\n",
    "\n",
    ". **Consistency** (we will check for duplicate values and how to handle them)\n",
    "\n",
    ". **Uniformity** ( we will check the data types as well as our columns naming for uniformity)\n",
    "\n",
    ". **Validity** (we will handlle irrelevant columns and  check for outliers )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPLETENESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "date                0\n",
       "price               0\n",
       "bedrooms            0\n",
       "bathrooms           0\n",
       "sqft_living         0\n",
       "sqft_lot            0\n",
       "floors              0\n",
       "waterfront       2376\n",
       "view               63\n",
       "condition           0\n",
       "grade               0\n",
       "sqft_above          0\n",
       "sqft_basement       0\n",
       "yr_built            0\n",
       "yr_renovated     3842\n",
       "zipcode             0\n",
       "lat                 0\n",
       "long                0\n",
       "sqft_living15       0\n",
       "sqft_lot15          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking and summing up our missing values in our data set\n",
    "kc_data_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to have missing values in our waterfront(2376),view(63) and yr_renovated(3842). We will have to investigate further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column waterfront has 2376 missing values, which is 11.0 % of it's total\n",
      "The column view has 63 missing values, which is 0.3 % of it's total\n",
      "The column yr_renovated has 3842 missing values, which is 17.8 % of it's total\n"
     ]
    }
   ],
   "source": [
    "# lets check for the percentage of missing values in our data set\n",
    "for col in kc_data_df.columns: # we are using a for loop to iterate over our data\n",
    "    if kc_data_df[col].isnull().sum() > 0:\n",
    "        percentage = (kc_data_df[col].isnull().sum()/len(kc_data_df[col]))*100\n",
    "        print(\"The column\", col,\"has\",kc_data_df[col].isnull().sum(),\"missing values, which is\", round(percentage, 1),\"% of it's total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets further check each column with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Waterfront column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check for the value count of the unique elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Waterfront Column\n",
      "\n",
      "Number of distinct elements is: 2 \n",
      "\n",
      "This is the count of unique values:\n",
      "waterfront\n",
      "NO     19075\n",
      "YES      146\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "The unique values:\n",
      "[nan 'NO' 'YES'] \n",
      "\n",
      "Number of missing values: 2376\n"
     ]
    }
   ],
   "source": [
    "#checking for unique elements value count\n",
    "print(\"The Waterfront Column\\n\")\n",
    "\n",
    "print(\"Number of distinct elements is:\", kc_data_df['waterfront'].nunique(),\"\\n\")\n",
    "\n",
    "print(\"This is the count of unique values:\")\n",
    "print(kc_data_df['waterfront'].value_counts(),\"\\n\")\n",
    "\n",
    "print('The unique values:')\n",
    "print(kc_data_df['waterfront'].unique(),\"\\n\")\n",
    "\n",
    "print(\"Number of missing values:\",kc_data_df['waterfront'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two unique values are YES and NO.NO is the most common value in this column with(19875) entries, whilst YES has just (146). This indicates that the majority of these homes lack a waterfront, hence it seems reasonable to presume that the homes with missing values  lack a waterfront. it is safe to substitute the missing values with NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waterfront\n",
      "NO     21451\n",
      "YES      146\n",
      "Name: count, dtype: int64\n",
      "['NO' 'YES']\n"
     ]
    }
   ],
   "source": [
    "# replacing missing values with 'NO'\n",
    "kc_data_df['waterfront'].fillna('NO',inplace=True)\n",
    "\n",
    "# confirming if the missing values have been replaced\n",
    "print(kc_data_df['waterfront'].value_counts())\n",
    "print(kc_data_df['waterfront'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The change was successful because the number of NO entries increased from 19875 to 21451."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###### View column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a function to get our unique elements and sum up there value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_counts(data, column): # creating a function for checking for unique elements and ther counts\n",
    "    print(\"Number of distinct elements in\", column, \"column:\", data[column].nunique())  # checking for unique elements in the column\n",
    "\n",
    "    value_counts = data[column].value_counts()  # counting the value of each unique element\n",
    "\n",
    "    # Use Series.apply with a Lambda Function\n",
    "    format_lambda = lambda x: f\"{x}: {value_counts[x]} ({value_counts[x] / len(data) * 100:.1f}%)\"\n",
    "\n",
    "    formatted_counts = value_counts.index.map(format_lambda)  # it will execute without creating the formatted_counts variable or printing its contents.\n",
    "    print(formatted_counts)\n",
    "\n",
    "    print(f\"\\nMissing values:\", data[column].isnull().sum())  # combining the information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct elements in view column: 5\n",
      "Index(['NONE: 19422 (89.9%)', 'AVERAGE: 957 (4.4%)', 'GOOD: 508 (2.4%)',\n",
      "       'FAIR: 330 (1.5%)', 'EXCELLENT: 317 (1.5%)'],\n",
      "      dtype='object', name='view')\n",
      "\n",
      "Missing values: 63\n"
     ]
    }
   ],
   "source": [
    "unique_counts(kc_data_df,'view')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this column, NONE is the most frequent unique element. This indicates that the 63 missing values are representing homes  that don't have a view. Hence I WILL substitute  the missing values with NONE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view\n",
      "NONE         19485\n",
      "AVERAGE        957\n",
      "GOOD           508\n",
      "FAIR           330\n",
      "EXCELLENT      317\n",
      "Name: count, dtype: int64\n",
      "['NONE' 'GOOD' 'EXCELLENT' 'AVERAGE' 'FAIR']\n"
     ]
    }
   ],
   "source": [
    "# replacing missing values with 'NONE'\n",
    "kc_data_df['view'].fillna('NONE',inplace=True)\n",
    "\n",
    "# confirming if the missing values have been replaced\n",
    "print(kc_data_df['view'].value_counts())\n",
    "print(kc_data_df['view'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes successfully made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Yr_renovated column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct elements in yr_renovated column: 70\n",
      "Index(['0.0: 17011 (78.8%)', '2014.0: 73 (0.3%)', '2013.0: 31 (0.1%)',\n",
      "       '2003.0: 31 (0.1%)', '2007.0: 30 (0.1%)', '2000.0: 29 (0.1%)',\n",
      "       '2005.0: 29 (0.1%)', '2004.0: 22 (0.1%)', '1990.0: 22 (0.1%)',\n",
      "       '2009.0: 21 (0.1%)', '2006.0: 20 (0.1%)', '1989.0: 20 (0.1%)',\n",
      "       '2002.0: 17 (0.1%)', '1984.0: 16 (0.1%)', '1991.0: 16 (0.1%)',\n",
      "       '1998.0: 16 (0.1%)', '2010.0: 15 (0.1%)', '1983.0: 15 (0.1%)',\n",
      "       '2001.0: 15 (0.1%)', '2008.0: 15 (0.1%)', '1999.0: 15 (0.1%)',\n",
      "       '1987.0: 14 (0.1%)', '1985.0: 14 (0.1%)', '1986.0: 14 (0.1%)',\n",
      "       '2015.0: 14 (0.1%)', '1994.0: 14 (0.1%)', '1992.0: 13 (0.1%)',\n",
      "       '1995.0: 12 (0.1%)', '1993.0: 12 (0.1%)', '1997.0: 12 (0.1%)',\n",
      "       '1988.0: 11 (0.1%)', '1996.0: 11 (0.1%)', '1970.0: 9 (0.0%)',\n",
      "       '2011.0: 9 (0.0%)', '2012.0: 8 (0.0%)', '1982.0: 8 (0.0%)',\n",
      "       '1980.0: 8 (0.0%)', '1968.0: 7 (0.0%)', '1979.0: 7 (0.0%)',\n",
      "       '1977.0: 7 (0.0%)', '1964.0: 5 (0.0%)', '1975.0: 5 (0.0%)',\n",
      "       '1965.0: 4 (0.0%)', '1981.0: 4 (0.0%)', '1963.0: 4 (0.0%)',\n",
      "       '1973.0: 4 (0.0%)', '1969.0: 4 (0.0%)', '1956.0: 3 (0.0%)',\n",
      "       '1955.0: 3 (0.0%)', '1972.0: 3 (0.0%)', '1960.0: 3 (0.0%)',\n",
      "       '1978.0: 3 (0.0%)', '1958.0: 3 (0.0%)', '1945.0: 3 (0.0%)',\n",
      "       '1957.0: 2 (0.0%)', '1940.0: 2 (0.0%)', '1962.0: 2 (0.0%)',\n",
      "       '1974.0: 2 (0.0%)', '1967.0: 2 (0.0%)', '1971.0: 1 (0.0%)',\n",
      "       '1944.0: 1 (0.0%)', '1950.0: 1 (0.0%)', '1934.0: 1 (0.0%)',\n",
      "       '1954.0: 1 (0.0%)', '1959.0: 1 (0.0%)', '1951.0: 1 (0.0%)',\n",
      "       '1953.0: 1 (0.0%)', '1946.0: 1 (0.0%)', '1976.0: 1 (0.0%)',\n",
      "       '1948.0: 1 (0.0%)'],\n",
      "      dtype='object', name='yr_renovated')\n",
      "\n",
      "Missing values: 3842\n"
     ]
    }
   ],
   "source": [
    "unique_counts(kc_data_df,'yr_renovated' )# using the unique_count function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The years span from 1948–2014 and 0.0 is the most frequent value thus  we'll replace the missing values with 0.0 because we don't know what 0.0 means based  on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yr_renovated\n",
      "0.0       20853\n",
      "2014.0       73\n",
      "2013.0       31\n",
      "2003.0       31\n",
      "2007.0       30\n",
      "          ...  \n",
      "1951.0        1\n",
      "1953.0        1\n",
      "1946.0        1\n",
      "1976.0        1\n",
      "1948.0        1\n",
      "Name: count, Length: 70, dtype: int64\n",
      "[   0. 1991. 2002. 2010. 1992. 2013. 1994. 1978. 2005. 2003. 1984. 1954.\n",
      " 2014. 2011. 1983. 1945. 1990. 1988. 1977. 1981. 1995. 2000. 1999. 1998.\n",
      " 1970. 1989. 2004. 1986. 2007. 1987. 2006. 1985. 2001. 1980. 1971. 1979.\n",
      " 1997. 1950. 1969. 1948. 2009. 2015. 1974. 2008. 1968. 2012. 1963. 1951.\n",
      " 1962. 1953. 1993. 1996. 1955. 1982. 1956. 1940. 1976. 1946. 1975. 1964.\n",
      " 1973. 1957. 1959. 1960. 1967. 1965. 1934. 1972. 1944. 1958.]\n"
     ]
    }
   ],
   "source": [
    "# replacing missing values with '0.0'\n",
    "kc_data_df['yr_renovated'].fillna(0.0,inplace=True)\n",
    "\n",
    "# confirming if the missing values have been replaced\n",
    "print(kc_data_df['yr_renovated'].value_counts())\n",
    "print(kc_data_df['yr_renovated'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The changes are made successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "date             0\n",
       "price            0\n",
       "bedrooms         0\n",
       "bathrooms        0\n",
       "sqft_living      0\n",
       "sqft_lot         0\n",
       "floors           0\n",
       "waterfront       0\n",
       "view             0\n",
       "condition        0\n",
       "grade            0\n",
       "sqft_above       0\n",
       "sqft_basement    0\n",
       "yr_built         0\n",
       "yr_renovated     0\n",
       "zipcode          0\n",
       "lat              0\n",
       "long             0\n",
       "sqft_living15    0\n",
       "sqft_lot15       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if there are any more missing values\n",
    "kc_data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### CONSISTENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for duplicate values\n",
    "kc_data_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNIFORMITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting  Data Types of Values in Columns from Object  to Float**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sqft_basement values are in objects data type, given that this column has numeric values.  let's try to investigate  the reason why the datatype isn't a float or integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqft_basement\n",
       "0.0       12826\n",
       "?           454\n",
       "600.0       217\n",
       "500.0       209\n",
       "700.0       208\n",
       "          ...  \n",
       "1920.0        1\n",
       "3480.0        1\n",
       "2730.0        1\n",
       "2720.0        1\n",
       "248.0         1\n",
       "Name: count, Length: 304, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc_data_df['sqft_basement'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These values represented by \"?\" string can be regarded as null values. We  will replace the \"?\"  with 0.0, because the majority of the values are at 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing the ? with 0.0\n",
    "kc_data_df['sqft_basement'].replace('?','0.0',inplace=True)\n",
    "\n",
    "#converting column to data type 'float'\n",
    "kc_data_df['sqft_basement'] = kc_data_df['sqft_basement'].astype(float)\n",
    "\n",
    "#confirming the change \n",
    "kc_data_df['sqft_basement'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully changed the data type to  a float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Converting the Date Column to month and year and Creating  new Columns  month and year**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The month and year the houses were sold are shown in the date column and data can be analysed easily by creating new columns called year and month  from this column, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after splitting date:\n",
      "           id     price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
      "0  7129300520  221900.0         3       1.00         1180      5650     1.0   \n",
      "1  6414100192  538000.0         3       2.25         2570      7242     2.0   \n",
      "2  5631500400  180000.0         2       1.00          770     10000     1.0   \n",
      "3  2487200875  604000.0         4       3.00         1960      5000     1.0   \n",
      "4  1954400510  510000.0         3       2.00         1680      8080     1.0   \n",
      "\n",
      "  waterfront  view  condition  ... sqft_basement  yr_built  yr_renovated  \\\n",
      "0         NO  NONE    Average  ...           0.0      1955           0.0   \n",
      "1         NO  NONE    Average  ...         400.0      1951        1991.0   \n",
      "2         NO  NONE    Average  ...           0.0      1933           0.0   \n",
      "3         NO  NONE  Very Good  ...         910.0      1965           0.0   \n",
      "4         NO  NONE    Average  ...           0.0      1987           0.0   \n",
      "\n",
      "   zipcode      lat     long  sqft_living15  sqft_lot15  month_sold  year_sold  \n",
      "0    98178  47.5112 -122.257           1340        5650          10       2014  \n",
      "1    98125  47.7210 -122.319           1690        7639          12       2014  \n",
      "2    98028  47.7379 -122.233           2720        8062           2       2015  \n",
      "3    98136  47.5208 -122.393           1360        5000          12       2014  \n",
      "4    98074  47.6168 -122.045           1800        7503           2       2015  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Spliting the date into month, day, and year\n",
    "date_split = kc_data_df['date'].str.split('/', expand=True)\n",
    "\n",
    "# Creating new columns for month and year and converting the values to integers\n",
    "kc_data_df['month_sold'] = date_split[0].astype(int)\n",
    "kc_data_df['year_sold'] = date_split[2].astype(int)\n",
    "\n",
    "# Droping the original date column\n",
    "kc_data_df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Verifying the changes\n",
    "print(\"DataFrame after splitting date:\")\n",
    "print(kc_data_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can seen the two columns have been  created and added to our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VALIDITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#checking for outliers using intequatrile for each column\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m Q1 \u001b[38;5;241m=\u001b[39m kc_data_df\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.25\u001b[39m) \u001b[38;5;66;03m# First quartile\u001b[39;00m\n\u001b[0;32m      4\u001b[0m Q3 \u001b[38;5;241m=\u001b[39m kc_data_df\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.75\u001b[39m) \u001b[38;5;66;03m# Third quartile\u001b[39;00m\n\u001b[0;32m      5\u001b[0m IQR \u001b[38;5;241m=\u001b[39m Q3 \u001b[38;5;241m-\u001b[39m Q1\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10882\u001b[0m, in \u001b[0;36mDataFrame.quantile\u001b[1;34m(self, q, axis, numeric_only, interpolation, method)\u001b[0m\n\u001b[0;32m  10875\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m  10877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(q):\n\u001b[0;32m  10878\u001b[0m     \u001b[38;5;66;03m# BlockManager.quantile expects listlike, so we wrap and unwrap here\u001b[39;00m\n\u001b[0;32m  10879\u001b[0m     \u001b[38;5;66;03m# error: List item 0 has incompatible type \"Union[float, Union[Union[\u001b[39;00m\n\u001b[0;32m  10880\u001b[0m     \u001b[38;5;66;03m# ExtensionArray, ndarray[Any, Any]], Index, Series], Sequence[float]]\";\u001b[39;00m\n\u001b[0;32m  10881\u001b[0m     \u001b[38;5;66;03m# expected \"float\"\u001b[39;00m\n\u001b[1;32m> 10882\u001b[0m     res_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantile(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m  10883\u001b[0m         [q],\n\u001b[0;32m  10884\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m  10885\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m  10886\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m  10887\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m  10888\u001b[0m     )\n\u001b[0;32m  10889\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  10890\u001b[0m         res \u001b[38;5;241m=\u001b[39m res_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10927\u001b[0m, in \u001b[0;36mDataFrame.quantile\u001b[1;34m(self, q, axis, numeric_only, interpolation, method)\u001b[0m\n\u001b[0;32m  10923\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m  10924\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Method must be in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  10925\u001b[0m     )\n\u001b[0;32m  10926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m> 10927\u001b[0m     res \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mquantile(qs\u001b[38;5;241m=\u001b[39mq, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39minterpolation)\n\u001b[0;32m  10928\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  10929\u001b[0m     valid_interpolation \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigher\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1587\u001b[0m, in \u001b[0;36mBlockManager.quantile\u001b[1;34m(self, qs, axis, interpolation)\u001b[0m\n\u001b[0;32m   1584\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   1585\u001b[0m new_axes[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m Index(qs, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m-> 1587\u001b[0m blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1588\u001b[0m     blk\u001b[38;5;241m.\u001b[39mquantile(axis\u001b[38;5;241m=\u001b[39maxis, qs\u001b[38;5;241m=\u001b[39mqs, interpolation\u001b[38;5;241m=\u001b[39minterpolation)\n\u001b[0;32m   1589\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m   1590\u001b[0m ]\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(blocks, new_axes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1588\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1584\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   1585\u001b[0m new_axes[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m Index(qs, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m   1587\u001b[0m blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m-> 1588\u001b[0m     blk\u001b[38;5;241m.\u001b[39mquantile(axis\u001b[38;5;241m=\u001b[39maxis, qs\u001b[38;5;241m=\u001b[39mqs, interpolation\u001b[38;5;241m=\u001b[39minterpolation)\n\u001b[0;32m   1589\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m   1590\u001b[0m ]\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(blocks, new_axes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1463\u001b[0m, in \u001b[0;36mBlock.quantile\u001b[1;34m(self, qs, interpolation, axis)\u001b[0m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# only ever called this way\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m is_list_like(qs)  \u001b[38;5;66;03m# caller is responsible for this\u001b[39;00m\n\u001b[1;32m-> 1463\u001b[0m result \u001b[38;5;241m=\u001b[39m quantile_compat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, np\u001b[38;5;241m.\u001b[39masarray(qs\u001b[38;5;241m.\u001b[39m_values), interpolation)\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;66;03m# ensure_block_shape needed for cases where we start with EA and result\u001b[39;00m\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;66;03m#  is ndarray, e.g. IntegerArray, SparseArray\u001b[39;00m\n\u001b[0;32m   1466\u001b[0m result \u001b[38;5;241m=\u001b[39m ensure_block_shape(result, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:37\u001b[0m, in \u001b[0;36mquantile_compat\u001b[1;34m(values, qs, interpolation)\u001b[0m\n\u001b[0;32m     35\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m na_value_for_dtype(values\u001b[38;5;241m.\u001b[39mdtype, compat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     36\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m quantile_with_mask(values, mask, fill_value, qs, interpolation)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_quantile(qs, interpolation)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:95\u001b[0m, in \u001b[0;36mquantile_with_mask\u001b[1;34m(values, mask, fill_value, qs, interpolation)\u001b[0m\n\u001b[0;32m     93\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(flat, \u001b[38;5;28mlen\u001b[39m(values))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(values), \u001b[38;5;28mlen\u001b[39m(qs))\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m _nanpercentile(\n\u001b[0;32m     96\u001b[0m         values,\n\u001b[0;32m     97\u001b[0m         qs \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100.0\u001b[39m,\n\u001b[0;32m     98\u001b[0m         na_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m     99\u001b[0m         mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    100\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m    101\u001b[0m     )\n\u001b[0;32m    103\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    104\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:216\u001b[0m, in \u001b[0;36m_nanpercentile\u001b[1;34m(values, qs, na_value, mask, interpolation)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mpercentile(\n\u001b[0;32m    217\u001b[0m         values,\n\u001b[0;32m    218\u001b[0m         qs,\n\u001b[0;32m    219\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;66;03m# error: No overload variant of \"percentile\" matches argument types\u001b[39;00m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;66;03m# \"ndarray[Any, Any]\", \"ndarray[Any, dtype[floating[_64Bit]]]\",\u001b[39;00m\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;66;03m# \"int\", \"Dict[str, str]\"  [call-overload]\u001b[39;00m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{np_percentile_argname: interpolation},  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mpercentile\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:4205\u001b[0m, in \u001b[0;36mpercentile\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[0;32m   4203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantile_is_valid(q):\n\u001b[0;32m   4204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentiles must be in the range [0, 100]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 4205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _quantile_unchecked(\n\u001b[0;32m   4206\u001b[0m     a, q, axis, out, overwrite_input, method, keepdims)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:4473\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001b[0m\n\u001b[0;32m   4465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantile_unchecked\u001b[39m(a,\n\u001b[0;32m   4466\u001b[0m                         q,\n\u001b[0;32m   4467\u001b[0m                         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4470\u001b[0m                         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4471\u001b[0m                         keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   4472\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ureduce(a,\n\u001b[0;32m   4474\u001b[0m                     func\u001b[38;5;241m=\u001b[39m_quantile_ureduce_func,\n\u001b[0;32m   4475\u001b[0m                     q\u001b[38;5;241m=\u001b[39mq,\n\u001b[0;32m   4476\u001b[0m                     keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[0;32m   4477\u001b[0m                     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   4478\u001b[0m                     out\u001b[38;5;241m=\u001b[39mout,\n\u001b[0;32m   4479\u001b[0m                     overwrite_input\u001b[38;5;241m=\u001b[39moverwrite_input,\n\u001b[0;32m   4480\u001b[0m                     method\u001b[38;5;241m=\u001b[39mmethod)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:3752\u001b[0m, in \u001b[0;36m_ureduce\u001b[1;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[0;32m   3749\u001b[0m             index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[0;32m   3750\u001b[0m             kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[1;32m-> 3752\u001b[0m r \u001b[38;5;241m=\u001b[39m func(a, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:4639\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[1;34m(a, q, axis, out, overwrite_input, method)\u001b[0m\n\u001b[0;32m   4637\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4638\u001b[0m         arr \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m-> 4639\u001b[0m result \u001b[38;5;241m=\u001b[39m _quantile(arr,\n\u001b[0;32m   4640\u001b[0m                    quantiles\u001b[38;5;241m=\u001b[39mq,\n\u001b[0;32m   4641\u001b[0m                    axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   4642\u001b[0m                    method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   4643\u001b[0m                    out\u001b[38;5;241m=\u001b[39mout)\n\u001b[0;32m   4644\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:4756\u001b[0m, in \u001b[0;36m_quantile\u001b[1;34m(arr, quantiles, axis, method, out)\u001b[0m\n\u001b[0;32m   4754\u001b[0m     result_shape \u001b[38;5;241m=\u001b[39m virtual_indexes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m (arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   4755\u001b[0m     gamma \u001b[38;5;241m=\u001b[39m gamma\u001b[38;5;241m.\u001b[39mreshape(result_shape)\n\u001b[1;32m-> 4756\u001b[0m     result \u001b[38;5;241m=\u001b[39m _lerp(previous,\n\u001b[0;32m   4757\u001b[0m                    \u001b[38;5;28mnext\u001b[39m,\n\u001b[0;32m   4758\u001b[0m                    gamma,\n\u001b[0;32m   4759\u001b[0m                    out\u001b[38;5;241m=\u001b[39mout)\n\u001b[0;32m   4760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(slices_having_nans):\n\u001b[0;32m   4761\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4762\u001b[0m         \u001b[38;5;66;03m# can't write to a scalar\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:4573\u001b[0m, in \u001b[0;36m_lerp\u001b[1;34m(a, b, t, out)\u001b[0m\n\u001b[0;32m   4559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lerp\u001b[39m(a, b, t, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   4560\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4561\u001b[0m \u001b[38;5;124;03m    Compute the linear interpolation weighted by gamma on each point of\u001b[39;00m\n\u001b[0;32m   4562\u001b[0m \u001b[38;5;124;03m    two same shape array.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4571\u001b[0m \u001b[38;5;124;03m        Output array.\u001b[39;00m\n\u001b[0;32m   4572\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4573\u001b[0m     diff_b_a \u001b[38;5;241m=\u001b[39m subtract(b, a)\n\u001b[0;32m   4574\u001b[0m     \u001b[38;5;66;03m# asanyarray is a stop-gap until gh-13105\u001b[39;00m\n\u001b[0;32m   4575\u001b[0m     lerp_interpolation \u001b[38;5;241m=\u001b[39m asanyarray(add(a, diff_b_a \u001b[38;5;241m*\u001b[39m t, out\u001b[38;5;241m=\u001b[39mout))\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "#checking for outliers using intequatrile for each column\n",
    "\n",
    "Q1 = kc_data_df.quantile(0.25) # First quartile\n",
    "Q3 = kc_data_df.quantile(0.75) # Third quartile\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have the above outliers lets visualize them using boxplots to investigate further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting box plots to visualize our outliers\n",
    "# Creating a list of column names excluding non-numeric columns (if any)\n",
    "numeric_columns = kc_data_df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Seting up the figure and axes\n",
    "fig, axes = plt.subplots(nrows=len(numeric_columns), figsize=(10, 6 * len(numeric_columns)))\n",
    "\n",
    "# Iterating over each numeric column and create a boxplot\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    ax = axes[i] if len(numeric_columns) > 1 else axes  # If there's only one numeric column, axes is not a list\n",
    "    \n",
    "    # Creating the boxplots\n",
    "    sns.boxplot(x=kc_data_df[column], ax=ax)\n",
    "    \n",
    "    # Seting titles and labels\n",
    "    ax.set_title(f'Boxplot of {column}')\n",
    "    ax.set_xlabel(column)\n",
    "    \n",
    "\n",
    "plt.tight_layout(pad=3.0)  # Adjusting the spacing between subplots\n",
    "plt.subplots_adjust(top=0.95)  # Adjusting the top margin to accommodate titles   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant amount of outliers in a number of our columns let remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the outliers \n",
    "outliers_df_iqr = kc_data_df[~((kc_data_df < (Q1 - 1.5 * IQR)) |(kc_data_df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "print(outliers_df_iqr.shape) # The number of rows and columns in the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data_df = outliers_df_iqr # storing our cleaned data in our original variable kc_data_df\n",
    "kc_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have removed our outliers  since they would have affected our model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create additional columns to determine the age of a house by getting the differnce between 2015 (that's when the data was last recorded) the reference year and yr_built, and another column age of the house after renovation by also getting the difference between 2015 and yr_renovated  \n",
    "\n",
    "These new columns will help to determine whether the age of built or renovation has an impact on the price of the house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column 'age_built' showing the age of house since its was built upto 2015\n",
    "kc_data_df['age_built'] = 2015 - kc_data_df['yr_built']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new column 'age_renovated'showing the age of a house after renovation\n",
    "kc_data_df['age_renovated'] = 2015 - kc_data_df['yr_renovated'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data_df.columns # checking to see if the two columns have been added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data_df.head(10) # viewing the first ten rows of our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets create a new column named  season_sold that tell us which at which season was a specific house sold at these will helps us to identify which season had the most sales and whether season determines the price of a house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a season dictonary using months in numerical order\n",
    "season_dict = {1:'Winter',\n",
    "           2:'Winter',\n",
    "           3:'Spring',\n",
    "           4:'Spring',\n",
    "           5:'Spring',\n",
    "           6:'Summer',\n",
    "           7:'Summer',\n",
    "           8:'Summer',\n",
    "           9:'Fall',\n",
    "           10:'Fall',\n",
    "           11:'Fall',\n",
    "           12:'Winter'}\n",
    "# creating a new column and mapping it to season_dict\n",
    "kc_data_df['season_sold'] = kc_data_df['month_sold'].map(season_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data_df # checking if the new column was added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start on Simple Linear Regressions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
